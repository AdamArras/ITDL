{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b02247aa",
      "metadata": {
        "id": "b02247aa"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b13d381",
      "metadata": {
        "id": "6b13d381"
      },
      "source": [
        "# Colab Starter Notebook — Introduction to Deep Learning\n",
        "Created: 2025-09-03 09:34 UTC\n",
        "\n",
        "This notebook is designed for engineering students to **start training deep learning models**.\n",
        "\n",
        "**What you'll do:**\n",
        "\n",
        "0. Get familiar with notesbooks\n",
        "1. Turn on GPU in Colab.\n",
        "2. Check your environment.\n",
        "3. Train a small image classifier (MNIST sample) using **fastai**.\n",
        "4. Evaluate, export, and turn in your results.\n",
        "5. Do a short assignment at the end.\n",
        "\n",
        "> **Instructor note:** Duplicate this notebook per lesson. Keep the structure (Setup → Data → Train → Evaluate → Save → Assignment).\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 0) Get familiar with notesbooks\n",
        "- Go to **Runtime → Change runtime type → Hardware accelerator → GPU → Save**.\n",
        "- Then run the cells below."
      ],
      "metadata": {
        "id": "7mqFrm0NKmP4",
        "outputId": "5b8e91a9-5c52-44a4-9f3b-c771401c1ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "id": "7mqFrm0NKmP4",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid character '→' (U+2192) (ipython-input-4151143347.py, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4151143347.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    - Go to **Runtime → Change runtime type → Hardware accelerator → GPU → Save**.\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '→' (U+2192)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0) Get familiar with notesbooks\n",
        "\n",
        "# 👋 Welcome to Jupyter/Colab Notebooks\n",
        "\n",
        "- A **notebook** is made of two types of cells:\n",
        "  1. **Code cells** → where you write and run Python code.\n",
        "  2. **Markdown cells** → where you write text, formulas, or explanations.\n",
        "\n",
        "- To run a cell:  \n",
        "  - Click inside it and press **Shift + Enter** (or the ▶️ button on the left).\n",
        "\n",
        "- Try it below! 👇\n"
      ],
      "metadata": {
        "id": "FSDUel8_KhW0"
      },
      "id": "FSDUel8_KhW0"
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a Python code cell\n",
        "# Run it with Shift+Enter\n",
        "\n",
        "print(\"Hello Deep Learning 👋\")"
      ],
      "metadata": {
        "id": "SGEJcGOZK9vb"
      },
      "id": "SGEJcGOZK9vb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ Exercise:\n",
        "- Change the message above to print your name.\n",
        "- Add a new cell below (Insert → Code Cell) and try some math, e.g. 2+3*4."
      ],
      "metadata": {
        "id": "ojq5Qg-_LGj_"
      },
      "id": "ojq5Qg-_LGj_"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Enable GPU in Colab\n",
        "- Go to **Runtime → Change runtime type → Hardware accelerator → GPU → Save**.\n",
        "- Then run the cells below."
      ],
      "metadata": {
        "id": "gZL-CJFaKk1G"
      },
      "id": "gZL-CJFaKk1G"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "29c58f64",
      "metadata": {
        "id": "29c58f64",
        "outputId": "6bd9fd3d-0fc3-42ec-f172-d22dff02ee0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Sep  3 10:40:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8             10W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Quick GPU check (works only on Colab with GPU)\n",
        "!nvidia-smi || echo \"No NVIDIA GPU detected (that's OK if you're not on Colab).\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "16636702",
      "metadata": {
        "id": "16636702"
      },
      "outputs": [],
      "source": [
        "# 2) Environment setup\n",
        "# If running on Colab, install/upgrade fastai. On local machines you can comment this out.\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "if IN_COLAB:\n",
        "    !pip -q install -U fastai fastdownload timm\n",
        "else:\n",
        "    print(\"Not in Colab (detected). If packages are missing, install fastai: pip install fastai fastdownload timm\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "303b8016",
      "metadata": {
        "id": "303b8016",
        "outputId": "654eca03-ce29-4e75-bc7a-2a6067402da8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: True\n",
            "GPU name: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "# 3) Imports and device info\n",
        "import torch\n",
        "from fastai.vision.all import *\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"Running on CPU\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23fbdd9d",
      "metadata": {
        "id": "23fbdd9d"
      },
      "outputs": [],
      "source": [
        "# 4) Reproducibility (set seeds)\n",
        "set_seed(42, reproducible=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aedd8a55",
      "metadata": {
        "id": "aedd8a55"
      },
      "source": [
        "## 2) Data\n",
        "We'll use **MNIST_SAMPLE** (a tiny subset of MNIST: 3s and 7s) for a very fast demo.\n",
        "\n",
        "> **Tip:** Switch to a bigger dataset later (e.g., `URLs.MNIST`, `URLs.PETS`, or a custom dataset).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2a30322",
      "metadata": {
        "id": "b2a30322"
      },
      "outputs": [],
      "source": [
        "from fastai.data.external import untar_data, URLs\n",
        "from fastai.vision.all import ImageDataLoaders\n",
        "\n",
        "path = untar_data(URLs.MNIST_SAMPLE)  # very small dataset: digits 3 vs 7\n",
        "print(\"Data path:\", path)\n",
        "\n",
        "dls = ImageDataLoaders.from_folder(\n",
        "    path,\n",
        "    train='train',\n",
        "    valid='valid',\n",
        "    valid_pct=None,     # use provided valid split\n",
        "    item_tfms=Resize(224),  # adapt images to a size suitable for pretrained models\n",
        "    bs=64\n",
        ")\n",
        "dls.show_batch(max_n=8)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "194cf006",
      "metadata": {
        "id": "194cf006"
      },
      "source": [
        "## 3) Train a classifier\n",
        "We'll train a **ResNet18** classifier with **fastai** and measure accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb4903a1",
      "metadata": {
        "id": "fb4903a1"
      },
      "outputs": [],
      "source": [
        "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
        "learn.fine_tune(1)  # keep it fast; increase epochs for better accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ad47f00",
      "metadata": {
        "id": "6ad47f00"
      },
      "source": [
        "## 4) Evaluate\n",
        "Look at sample predictions and the confusion matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ad80d7",
      "metadata": {
        "id": "56ad80d7"
      },
      "outputs": [],
      "source": [
        "# Sample predictions\n",
        "interp = ClassificationInterpretation.from_learner(learn)\n",
        "interp.plot_confusion_matrix(figsize=(4,4))\n",
        "plt.show()\n",
        "\n",
        "# Show top losses\n",
        "interp.plot_top_losses(6, nrows=2, figsize=(6,6))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "578326d5",
      "metadata": {
        "id": "578326d5"
      },
      "source": [
        "## 5) Save and Inference\n",
        "Export your trained model and try loading it back for inference.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a77e229d",
      "metadata": {
        "id": "a77e229d"
      },
      "outputs": [],
      "source": [
        "# Export the learner to a file\n",
        "model_path = 'mnist_sample_resnet18.pkl'\n",
        "learn.export(model_path)\n",
        "print(f\"Model exported to {model_path}\")\n",
        "\n",
        "# Example: load the exported model and predict on a single image\n",
        "learn_inf = load_learner(model_path)\n",
        "test_img = (path/'valid'/'3').ls()[0]  # pick one example\n",
        "print(\"Testing on image:\", test_img)\n",
        "pred, pred_idx, probs = learn_inf.predict(test_img)\n",
        "print(\"Prediction:\", pred)\n",
        "print(\"Probabilities:\", probs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5b62e80",
      "metadata": {
        "id": "c5b62e80"
      },
      "source": [
        "## 6) (Optional) Timings & Resources\n",
        "If you need to compare GPU vs CPU, measure timings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db72eddd",
      "metadata": {
        "id": "db72eddd"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "start = time.time()\n",
        "_ = learn.dls.valid.one_batch()\n",
        "end = time.time()\n",
        "print(f\"One validation batch time: {end-start:.4f}s on this hardware.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89bc51cb",
      "metadata": {
        "id": "89bc51cb"
      },
      "source": [
        "## 7) Assignment (Turn this in)\n",
        "1. **Change the model or hyperparameters:** try `resnet34` or increase `fine_tune(3)` and report the new accuracy.\n",
        "2. **Augmentations:** add `batch_tfms=aug_transforms(do_flip=False, max_rotate=15, max_zoom=1.1)` to `ImageDataLoaders.from_folder` and report the impact.\n",
        "3. **Learning rate finder:** run `learn.lr_find()` and choose a learning rate; re-train and compare.\n",
        "4. **Explain:** In 3–5 sentences, explain the difference between **loss** and **metric** in your own words.\n",
        "5. **Screenshot:** Include a screenshot of your confusion matrix and top losses.\n",
        "\n",
        "> **Deliverable:** A short report (Markdown cell below) plus the notebook with your final model exported.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c983f2d",
      "metadata": {
        "id": "2c983f2d"
      },
      "source": [
        "### Your short report\n",
        "*(Write here: what you changed, your observations, final accuracy, and a brief explanation of loss vs metric.)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d3ddd74",
      "metadata": {
        "id": "0d3ddd74"
      },
      "source": [
        "## 8) Teaching Notes (Instructor Only)\n",
        "- Emphasize **GPU vs CPU** and session limits in Colab.\n",
        "- Highlight the training loop high-level flow: **data → model → loss → optimizer → metric**.\n",
        "- Encourage students to **iterate quickly** on small datasets; scale up later.\n",
        "- Common pitfalls: not enabling GPU; RAM/session resets; forgetting to export models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b91d0ffb",
      "metadata": {
        "id": "b91d0ffb"
      },
      "source": [
        "## 9) Troubleshooting\n",
        "- **No GPU?** Re-check *Runtime → Change runtime type → GPU* and re-run setup.\n",
        "- **ImportError (fastai not found)?** Re-run the install cell.\n",
        "- **Out of memory (OOM)?** Lower `bs` (batch size), e.g., `bs=32`.\n",
        "- **Slow training?** Reduce image size in `Resize(128)` or use a smaller model.\n",
        "- **Session reset?** Save your work to Google Drive or GitHub frequently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f08af6de",
      "metadata": {
        "id": "f08af6de"
      },
      "source": [
        "## Appendix: (Optional) Minimal PyTorch Training Loop\n",
        "For students curious about what's under the hood, here's a very small PyTorch loop on random data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c94fc3",
      "metadata": {
        "id": "e5c94fc3"
      },
      "outputs": [],
      "source": [
        "# Educational only — a tiny loop on fake data to show the pattern\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "X = torch.randn(512, 28*28)\n",
        "y = (X.sum(dim=1) > 0).long()  # fake labels\n",
        "\n",
        "model = nn.Sequential(nn.Linear(28*28, 128), nn.ReLU(), nn.Linear(128, 2))\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "for epoch in range(3):\n",
        "    model.train()\n",
        "    opt.zero_grad()\n",
        "    preds = model(X)\n",
        "    loss = loss_fn(preds, y)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "    with torch.no_grad():\n",
        "        acc = (preds.argmax(dim=1) == y).float().mean().item()\n",
        "    print(f\"Epoch {epoch+1}: loss={loss.item():.4f}, acc={acc:.3f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b13d381",
   "metadata": {},
   "source": [
    "# Colab Starter Notebook — Practical Deep Learning\n",
    "Created: 2025-09-03 09:34 UTC\n",
    "\n",
    "This notebook is designed for engineering students to **start training deep learning models on Google Colab** with a GPU.\n",
    "\n",
    "**What you'll do:**\n",
    "1. Turn on GPU in Colab.\n",
    "2. Check your environment.\n",
    "3. Train a small image classifier (MNIST sample) using **fastai**.\n",
    "4. Evaluate, export, and turn in your results.\n",
    "5. Do a short assignment at the end.\n",
    "\n",
    "> **Instructor note:** Duplicate this notebook per lesson. Keep the structure (Setup → Data → Train → Evaluate → Save → Assignment).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02247aa",
   "metadata": {},
   "source": [
    "## 1) Enable GPU in Colab\n",
    "- Go to **Runtime → Change runtime type → Hardware accelerator → GPU → Save**.\n",
    "- Then run the cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c58f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick GPU check (works only on Colab with GPU)\n",
    "!nvidia-smi || echo \"No NVIDIA GPU detected (that's OK if you're not on Colab).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16636702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Environment setup\n",
    "# If running on Colab, install/upgrade fastai. On local machines you can comment this out.\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "if IN_COLAB:\n",
    "    !pip -q install -U fastai fastdownload timm\n",
    "else:\n",
    "    print(\"Not in Colab (detected). If packages are missing, install fastai: pip install fastai fastdownload timm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Imports and device info\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"Running on CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fbdd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Reproducibility (set seeds)\n",
    "set_seed(42, reproducible=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedd8a55",
   "metadata": {},
   "source": [
    "## 2) Data\n",
    "We'll use **MNIST_SAMPLE** (a tiny subset of MNIST: 3s and 7s) for a very fast demo.\n",
    "\n",
    "> **Tip:** Switch to a bigger dataset later (e.g., `URLs.MNIST`, `URLs.PETS`, or a custom dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a30322",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.external import untar_data, URLs\n",
    "from fastai.vision.all import ImageDataLoaders\n",
    "\n",
    "path = untar_data(URLs.MNIST_SAMPLE)  # very small dataset: digits 3 vs 7\n",
    "print(\"Data path:\", path)\n",
    "\n",
    "dls = ImageDataLoaders.from_folder(\n",
    "    path,\n",
    "    train='train',\n",
    "    valid='valid',\n",
    "    valid_pct=None,     # use provided valid split\n",
    "    item_tfms=Resize(224),  # adapt images to a size suitable for pretrained models\n",
    "    bs=64\n",
    ")\n",
    "dls.show_batch(max_n=8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194cf006",
   "metadata": {},
   "source": [
    "## 3) Train a classifier\n",
    "We'll train a **ResNet18** classifier with **fastai** and measure accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4903a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet18, metrics=accuracy)\n",
    "learn.fine_tune(1)  # keep it fast; increase epochs for better accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad47f00",
   "metadata": {},
   "source": [
    "## 4) Evaluate\n",
    "Look at sample predictions and the confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ad80d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample predictions\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix(figsize=(4,4))\n",
    "plt.show()\n",
    "\n",
    "# Show top losses\n",
    "interp.plot_top_losses(6, nrows=2, figsize=(6,6))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578326d5",
   "metadata": {},
   "source": [
    "## 5) Save and Inference\n",
    "Export your trained model and try loading it back for inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the learner to a file\n",
    "model_path = 'mnist_sample_resnet18.pkl'\n",
    "learn.export(model_path)\n",
    "print(f\"Model exported to {model_path}\")\n",
    "\n",
    "# Example: load the exported model and predict on a single image\n",
    "learn_inf = load_learner(model_path)\n",
    "test_img = (path/'valid'/'3').ls()[0]  # pick one example\n",
    "print(\"Testing on image:\", test_img)\n",
    "pred, pred_idx, probs = learn_inf.predict(test_img)\n",
    "print(\"Prediction:\", pred)\n",
    "print(\"Probabilities:\", probs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b62e80",
   "metadata": {},
   "source": [
    "## 6) (Optional) Timings & Resources\n",
    "If you need to compare GPU vs CPU, measure timings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db72eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "_ = learn.dls.valid.one_batch()\n",
    "end = time.time()\n",
    "print(f\"One validation batch time: {end-start:.4f}s on this hardware.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bc51cb",
   "metadata": {},
   "source": [
    "## 7) Assignment (Turn this in)\n",
    "1. **Change the model or hyperparameters:** try `resnet34` or increase `fine_tune(3)` and report the new accuracy.\n",
    "2. **Augmentations:** add `batch_tfms=aug_transforms(do_flip=False, max_rotate=15, max_zoom=1.1)` to `ImageDataLoaders.from_folder` and report the impact.\n",
    "3. **Learning rate finder:** run `learn.lr_find()` and choose a learning rate; re-train and compare.\n",
    "4. **Explain:** In 3–5 sentences, explain the difference between **loss** and **metric** in your own words.\n",
    "5. **Screenshot:** Include a screenshot of your confusion matrix and top losses.\n",
    "\n",
    "> **Deliverable:** A short report (Markdown cell below) plus the notebook with your final model exported.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c983f2d",
   "metadata": {},
   "source": [
    "### Your short report\n",
    "*(Write here: what you changed, your observations, final accuracy, and a brief explanation of loss vs metric.)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3ddd74",
   "metadata": {},
   "source": [
    "## 8) Teaching Notes (Instructor Only)\n",
    "- Emphasize **GPU vs CPU** and session limits in Colab.\n",
    "- Highlight the training loop high-level flow: **data → model → loss → optimizer → metric**.\n",
    "- Encourage students to **iterate quickly** on small datasets; scale up later.\n",
    "- Common pitfalls: not enabling GPU; RAM/session resets; forgetting to export models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91d0ffb",
   "metadata": {},
   "source": [
    "## 9) Troubleshooting\n",
    "- **No GPU?** Re-check *Runtime → Change runtime type → GPU* and re-run setup.\n",
    "- **ImportError (fastai not found)?** Re-run the install cell.\n",
    "- **Out of memory (OOM)?** Lower `bs` (batch size), e.g., `bs=32`.\n",
    "- **Slow training?** Reduce image size in `Resize(128)` or use a smaller model.\n",
    "- **Session reset?** Save your work to Google Drive or GitHub frequently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08af6de",
   "metadata": {},
   "source": [
    "## Appendix: (Optional) Minimal PyTorch Training Loop\n",
    "For students curious about what's under the hood, here's a very small PyTorch loop on random data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c94fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Educational only — a tiny loop on fake data to show the pattern\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "X = torch.randn(512, 28*28)\n",
    "y = (X.sum(dim=1) > 0).long()  # fake labels\n",
    "\n",
    "model = nn.Sequential(nn.Linear(28*28, 128), nn.ReLU(), nn.Linear(128, 2))\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    opt.zero_grad()\n",
    "    preds = model(X)\n",
    "    loss = loss_fn(preds, y)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    with torch.no_grad():\n",
    "        acc = (preds.argmax(dim=1) == y).float().mean().item()\n",
    "    print(f\"Epoch {epoch+1}: loss={loss.item():.4f}, acc={acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
